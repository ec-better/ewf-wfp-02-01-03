{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-wfp-02-01-03 - Long Term Averages of Land Surface Temperature Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Term Averages of Land Surface Temperature Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Long Term Averages of Land Surface Temperature Time Series'),\n",
    "                ('abstract', 'Long Term Averages of Land Surface Temperature Time Series'),\n",
    "                ('id', 'ewf-wfp-02-01-03')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = dict([('id', 'N_1'),\n",
    "            ('value', 'False'),\n",
    "            ('title', 'No Aggregation'),\n",
    "            ('abstract', 'No aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_3 = dict([('id', 'N_3'),\n",
    "            ('value', 'True'),\n",
    "            ('title', '30 Day Aggregation'),\n",
    "            ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_6 = dict([('id', 'N_6'),\n",
    "            ('value', 'False'),\n",
    "            ('title', '60 Day Aggregation'),\n",
    "            ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_9 = dict([('id', 'N_9'),\n",
    "            ('value', 'False'),\n",
    "            ('title', '90 Day Aggregation'),\n",
    "            ('abstract', 'Get a 90 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_12 = dict([('id', 'N_12'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '120 Day Aggregation'),\n",
    "             ('abstract', 'Get a 120 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_15 = dict([('id', 'N_15'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '150 Day Aggregation'),\n",
    "             ('abstract', 'Get a 150 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_18 = dict([('id', 'N_18'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '180 Day Aggregation'),\n",
    "             ('abstract', 'Get a 180 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_27 = dict([('id', 'N_27'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '270 Day Aggregation'),\n",
    "             ('abstract', 'Get a 270 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_36 = dict([('id', 'N_36'),\n",
    "             ('value', 'False'),\n",
    "             ('title', '360 Day Aggregation'),\n",
    "             ('abstract', 'Get a 360 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON((11.5030755518998 -11.1141633706909,41.0343255518998 -11.1141633706909,41.0343255518998 -34.9763656693858,11.5030755518998 -34.9763656693858,11.5030755518998 -11.1141633706909))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'SouthernAfrica'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAggCat = dict([('id', 'indexAggCat'),\n",
    "                    ('value', 'better-wfp-02-01-02'),\n",
    "                    ('title', 'indexAggCat'),\n",
    "                    ('abstract', 'index to access catalog of aggregated land surface temperature time series'),\n",
    "                    ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikeyAggCat = dict([('id', 'apikeyAggCat'),\n",
    "                     ('value', ''),\n",
    "                     ('title', 'apikeyAggCat'),\n",
    "                     ('abstract', 'apikey to access indexAggCat catalog'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = dict([('id', 'startdate'),\n",
    "                  ('value', '2015-01-01T00:00Z'),\n",
    "                  ('title', 'Start date'),\n",
    "                  ('abstract', 'Start date')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enddate = dict([('id', 'enddate'),\n",
    "                ('value', '2017-12-30T23:59Z'),\n",
    "                ('title', 'End date'),\n",
    "                ('abstract', 'End date')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = dict([('id', 'update'),\n",
    "               ('value', '2020-02-23T00:00Z/2020-03-09T00:00Z'),\n",
    "               ('title', 'update'),\n",
    "               ('abstract', 'update')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "'''\n",
    "catalogue_url = 'https://catalog.terradue.com/' + indexAggCat['value'] + '/search'\n",
    "    \n",
    "search_params =  dict([('start', startdate['value']),\n",
    "                      ('stop', enddate['value']),\n",
    "                      ('count', 'unlimited')])\n",
    "\n",
    "search = ciop.search(end_point=catalogue_url, \n",
    "                     params=search_params,\n",
    "                     output_fields='self,identifier,startdate,enddate,enclosure,title,updated', pagination = 100,\n",
    "                     model='GeoTime',creds='{}:{}'.format(indexAggCat['value'], apikeyAggCat['value']))\n",
    "\n",
    "\n",
    "input_metadata = pd.DataFrame.from_dict(search)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(input_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp\n",
    "'''\n",
    "prods = input_metadata[input_metadata['title'].str.contains('_maxvalues_') | input_metadata['title'].str.contains('_averages_')]\n",
    "prods = prods[prods['title'].str.contains('_N3_')]\n",
    "input_references = prods['self'].tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the MDOIS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('11FDFF9B817B413E6A54B7EE66A01EFCD51D80CB',\n",
    "                     '5CE2CE3D346E366EF188FB74B5E326F8906619E1',\n",
    "                     '8DEE5EBB41FE16B5AA9D37B4ABD50D9B61506D7E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references =  ('https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=11FDFF9B817B413E6A54B7EE66A01EFCD51D80CB',\n",
    "                     'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=5CE2CE3D346E366EF188FB74B5E326F8906619E1',\n",
    "                     'https://catalog.terradue.com/better-wfp-02-01-02/search?format=atom&uid=8DEE5EBB41FE16B5AA9D37B4ABD50D9B61506D7E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cioppy\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_cfolder(folder):\n",
    "    \n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "\n",
    "# get metadata from catalog\n",
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,title,startdate,enddate,wkt',creds='{}:{}'.format(indexAggCat['value'],apikeyAggCat['value']))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "\n",
    "    \n",
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def matrix_sum(mat1, mat2, no_data_value=None):\n",
    "    \n",
    "    if no_data_value is not None:\n",
    "        if not isinstance(mat1, int):\n",
    "            mat1[(mat1 == no_data_value)] = 0\n",
    "        if not isinstance(mat2, int):\n",
    "            mat2[(mat2 == no_data_value)] = 0\n",
    "            \n",
    "            \n",
    "    msum = np.add(mat1,mat2)\n",
    "        \n",
    "    msum[(mat1 == 0)] = 0\n",
    "    msum[(mat2 == 0)] = 0\n",
    "        \n",
    "    return msum\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, output_projection=None, output_geotransform=None, mask=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "        \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5])\n",
    "    \n",
    "    output.FlushCache()\n",
    "    \n",
    "def calc_average(matrix_list, n_years):\n",
    "    \n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    \n",
    "    result = matrix_list[0].astype('float64') \n",
    "    \n",
    "    \n",
    "    print(matrix_list[0][208,480])\n",
    "    \n",
    "    for i in range(1, n_years):\n",
    "        print(matrix_list[i].dtype)\n",
    "        result = matrix_sum(result, matrix_list[i].astype('float64') )\n",
    "        \n",
    "        print(matrix_list[i][208,480])\n",
    "        \n",
    "    print(result.dtype)\n",
    "    \n",
    "    #return np.divide(result, (n_years*1.00))\n",
    "    print(n_years*1.00)\n",
    "    #return np.true_divide(result, (n_years*1.00))\n",
    "    \n",
    "    return result / (n_years*1.00)\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "def calc_lta(file_list):\n",
    "    \n",
    "    if file_list:\n",
    "        \n",
    "        n_years = len(file_list)\n",
    "        \n",
    "        agr_period_matrix = get_matrix_list(file_list)\n",
    "        \n",
    "        print('Aggregations converted to matrices')\n",
    "        lta = calc_average(agr_period_matrix, n_years)\n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "        \n",
    "        return lta, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def write_output(temp_folder, lta, period_start_date, period_end_date, startLTAyear, endLTAyear, product_type, period_N, agr_type, region, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    \n",
    "    start_day_month = str(period_start_date.month) + '-' + str(period_start_date.day)\n",
    "    end_day_month = str(period_end_date.month) + '-' + str(period_end_date.day)\n",
    "  \n",
    "    output_name = os.path.join(temp_folder, 'LTA_' + product_type + '_' + region + '_' + str(period_N) + '_' + agr_type + '_' + start_day_month + '_' + end_day_month + '_' + str(startLTAyear) + '_' + str(endLTAyear) + '.tif')\n",
    "    \n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    \n",
    "    return output_name\n",
    "\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = dt.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))\n",
    "        \n",
    "# var - 'maxvalues' or 'averages'\n",
    "def select_refs (df_all_refs, N, var):\n",
    "    \n",
    "    # Filter by N\n",
    "    prodsNvar = df_all_refs[df_all_refs['title'].str.contains('_N{}_'.format(N))]\n",
    "    \n",
    "    # Filter by var\n",
    "    prodsNvar = prodsNvar[prodsNvar['title'].str.contains('_' + var + '_')]\n",
    "    \n",
    "    # sort by startdate\n",
    "    prodsNvar = prodsNvar.sort_values(by='startdate', ascending=True)\n",
    "    \n",
    "    #### Create lookup table\n",
    "\n",
    "    # column names - e.g. 01_10, 01_15, 01_25, ...\n",
    "    months_and_days = []\n",
    "\n",
    "    for m in range(12):\n",
    "        for d in ['05', '15', '25']:\n",
    "            months_and_days.append('{0:02}'.format(m+1) + '_' + d)\n",
    "\n",
    "    # row names - e.g. 2015, 2016, ...\n",
    "    firstdate = prodsNvar['startdate'].min().year\n",
    "    lastdate = prodsNvar['startdate'].max().year\n",
    "\n",
    "    start_years = range(firstdate,lastdate+1)\n",
    "\n",
    "    # create empty dataframe\n",
    "    matNvar = pd.DataFrame(index=start_years, columns=months_and_days)\n",
    "\n",
    "    #### Fill lookup table\n",
    "\n",
    "    for ii in prodsNvar.index:\n",
    "        dd = prodsNvar['startdate'].loc[ii]\n",
    "        #print(dd.year, '{0:02}_{1:02}'.format(dd.month, dd.day))\n",
    "        matNvar.at[dd.year, '{0:02}_{1:02}'.format(dd.month, dd.day)] = ii\n",
    "\n",
    "\n",
    "    \n",
    "    return prodsNvar, matNvar, months_and_days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata for all entries\n",
    "# store them in a dataframe\n",
    "message = 'Getting metadata' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "input_metada = get_input_metadata(input_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_metada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get N to process\n",
    "nlist = [N_1['value'], N_3['value'], N_6['value'], N_9['value'], N_12['value'], N_15['value'], N_18['value'], N_27['value'], N_36['value']]\n",
    "nlist = [n == 'True' for n in nlist]\n",
    "nvalues = [1, 3, 6, 9, 12, 15, 18, 27, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "for nv,ntf in zip(nvalues,nlist):\n",
    "        if ntf:\n",
    "            N = nv\n",
    "            break\n",
    "            \n",
    "prodsNvar, matNvar, months_and_days = select_refs(input_metada, N, 'averages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matNvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each month_day (e.g. 01_05, 01_15, 01_25, ...)\n",
    "for md in months_and_days:\n",
    "    \n",
    "    \n",
    "    # get list of all positions in prods\n",
    "    pp = matNvar[md].tolist()\n",
    "    # remove all NaN entries\n",
    "    pp = [e for e in pp if ~np.isnan(e)]\n",
    "    \n",
    "    # if there is at least one product available go ahead\n",
    "    if len(pp) >= 1:\n",
    "        \n",
    "        # create dataframe with the references for the LTA computation\n",
    "        dfbin = pd.DataFrame(columns=prodsNvar.columns)\n",
    "        for ii in pp:\n",
    "            dfbin = dfbin.append(prodsNvar.loc[ii], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "        message = 'computing LTA' \n",
    "        ciop.log('INFO', message)\n",
    "\n",
    "        # N time steps\n",
    "        nlist = [N_1['value'], N_3['value'], N_6['value'], N_9['value'], N_12['value'], N_15['value'], N_18['value'], N_27['value'], N_36['value']]\n",
    "        nlist = [n == 'True' for n in nlist]\n",
    "        nvalues = [1, 3, 6, 9, 12, 15, 18, 27, 36]\n",
    "\n",
    "        file_list = []\n",
    "        for bl,nv in zip(nlist, nvalues):\n",
    "    \n",
    "            # only works for selected N time steps\n",
    "            if bl:\n",
    "        \n",
    "                N = nv\n",
    "        \n",
    "                file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in dfbin['enclosure']]\n",
    "        \n",
    "                lta, projection, geotransform, no_data_value, data_type = calc_lta(file_list)\n",
    "\n",
    "        print('+++++++++++++++++++')\n",
    "        print(file_list)\n",
    "        \n",
    "        \n",
    "        message = 'Writing output' \n",
    "        ciop.log('INFO', message)\n",
    "\n",
    "\n",
    "        # get start and last date from metadata\n",
    "        startdate = dfbin['startdate'].min().strftime('%Y-%m-%d')\n",
    "        enddate = dfbin['enddate'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "        startLTAyear = int(dfbin['startdate'].min().strftime('%Y'))\n",
    "        endLTAyear = int(dfbin['startdate'].max().strftime('%Y'))\n",
    "\n",
    "        print(startLTAyear)\n",
    "        print(endLTAyear)\n",
    "\n",
    "\n",
    "        filename = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')\n",
    "\n",
    "        startdate = dt.datetime.strptime(startdate, '%Y-%m-%d')\n",
    "        enddate = dt.datetime.strptime(enddate, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "        agr = filename[3]\n",
    "        prod_type = filename[0]\n",
    "        N_value = filename[2]\n",
    "        region = filename[1]\n",
    "\n",
    "\n",
    "        #lta = None\n",
    "        if lta is not None:\n",
    "\n",
    "            filename = write_output(output_folder, lta, startdate, enddate, startLTAyear, endLTAyear, prod_type, N_value, agr, region, projection, geotransform, 'GTiff', no_data_value, data_type)\n",
    "            print(filename)\n",
    "            write_properties_file(filename, startdate, enddate, regionOfInterest['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(lta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Removing temporary files' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
