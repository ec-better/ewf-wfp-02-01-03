{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ewf-wfp-02-01-03 - Long Term Averages of Land Surface Temperature Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Term Averages of Land Surface Temperature Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Long Term Averages of Land Surface Temperature Time Series'),\n",
    "                ('abstract', 'Long Term Averages of Land Surface Temperature Time Series'),\n",
    "                ('id', 'ewf-wfp-02-01-03')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"parameter\">Parameter Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_1 = dict([('id', 'N_1'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', 'No Aggregation'),\n",
    "                          ('abstract', 'No aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_3 = dict([('id', 'N_3'),\n",
    "                          ('value', 'True'),\n",
    "                          ('title', '30 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_6 = dict([('id', 'N_6'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '60 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 30 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_9 = dict([('id', 'N_9'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '90 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 90 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_12 = dict([('id', 'N_12'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '120 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 120 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_15 = dict([('id', 'N_15'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '150 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 150 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_18 = dict([('id', 'N_18'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '180 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 180 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_27 = dict([('id', 'N_27'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '270 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 270 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " N_36 = dict([('id', 'N_36'),\n",
    "                          ('value', 'False'),\n",
    "                          ('title', '360 Day Aggregation'),\n",
    "                          ('abstract', 'Get a 360 day aggregation')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON((11.5030755518998 -11.1141633706909,41.0343255518998 -11.1141633706909,41.0343255518998 -34.9763656693858,11.5030755518998 -34.9763656693858,11.5030755518998 -11.1141633706909))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'SouthernAfrica'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexAggCat = dict([('id', 'indexAggCat'),\n",
    "             ('value', 'better-wfp-02-01-02'),\n",
    "             ('title', 'indexAggCat'),\n",
    "             ('abstract', 'index to access catalog of aggregated land surface temperature time series'),\n",
    "             ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikeyAggCat = dict([('id', 'apikeyAggCat'),\n",
    "                ('value', ''),\n",
    "                ('title', 'apikeyAggCat'),\n",
    "                ('abstract', 'apikey to access indexAggCat catalog'),\n",
    "                ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the MDOIS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('0009d1c7-e754-4b77-8811-7de9d0436d5c/LST_SouthernAfrica_N3_averages_2015-01-05_2015-01-25.tif',\n",
    "                     '36bc25f2-1b40-4514-8bf0-f6b6883f499a/LST_SouthernAfrica_N3_averages_2016-01-05_2016-01-25.tif',\n",
    "                     '032cf334-c40a-4c24-b504-169f37dc562f/LST_SouthernAfrica_N3_averages_2017-01-05_2017-01-25.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references =  ('http://sb-10-150-0-22.better.terradue.int:80/sbws/wps/ewf-wfp-02-01-02/0000019-190801000013916-oozie-oozi-W/results/search?id=0009d1c7-e754-4b77-8811-7de9d0436d5c/LST_SouthernAfrica_N3_averages_2015-01-05_2015-01-25.tif',\n",
    "                     'http://sb-10-150-0-22.better.terradue.int:80/sbws/wps/ewf-wfp-02-01-02/0000020-190801000013916-oozie-oozi-W/results/search?id=36bc25f2-1b40-4514-8bf0-f6b6883f499a/LST_SouthernAfrica_N3_averages_2016-01-05_2016-01-25.tif',\n",
    "                     'http://sb-10-150-0-22.better.terradue.int:80/sbws/wps/ewf-wfp-02-01-02/0000021-190801000013916-oozie-oozi-W/results/search?id=032cf334-c40a-4c24-b504-169f37dc562f/LST_SouthernAfrica_N3_averages_2017-01-05_2017-01-25.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/modis/outputs/output02\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import pdb\n",
    "\n",
    "ciop = cioppy.Cioppy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_results = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_cfolder(folder):\n",
    "    \n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    \n",
    "\n",
    "# get metadata from catalog\n",
    "def get_input_metadata (input_refs):\n",
    "    \n",
    "    # for each product get metadata\n",
    "    Result_Prod = []\n",
    "    \n",
    "    for index,product_ref in enumerate(input_refs):\n",
    "        \n",
    "        # since the search is by identifier \n",
    "        Result_Prod.append(ciop.search(end_point = product_ref,params =[],output_fields='self,identifier,startdate,enclosure,title,startdate,enddate,wkt',creds='{}:{}'.format(indexAggCat['value'],apikeyAggCat['value']))[0] )\n",
    "    \n",
    "\n",
    "    input_metadata = gpd.GeoDataFrame.from_dict(Result_Prod)\n",
    "\n",
    "    input_metadata['startdate'] = pd.to_datetime(input_metadata['startdate'])\n",
    "    input_metadata['enddate'] = pd.to_datetime(input_metadata['enddate'])\n",
    "    \n",
    "    return input_metadata\n",
    "\n",
    "\n",
    "    \n",
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "\n",
    "def matrix_sum(mat1, mat2, no_data_value=None):\n",
    "    if no_data_value is not None:\n",
    "        if not isinstance(mat1, int):\n",
    "            mat1[(mat1 == no_data_value)] = 0\n",
    "        if not isinstance(mat2, int):\n",
    "            mat2[(mat2 == no_data_value)] = 0\n",
    "            \n",
    "            \n",
    "    msum = mat1 + mat2\n",
    "        \n",
    "    msum[(mat1 == 0)] = 0\n",
    "    msum[(mat2 == 0)] = 0\n",
    "        \n",
    "    return msum\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, output_projection=None, output_geotransform=None, mask=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    if mask is not None:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "        \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "    \n",
    "    output.FlushCache()\n",
    "    \n",
    "def calc_average(matrix_list, n_years):\n",
    "    if not isinstance(matrix_list, list):\n",
    "        return 0\n",
    "    result = matrix_list[0]\n",
    "    for i in range(1, n_years):\n",
    "        result = matrix_sum(result, matrix_list[i])\n",
    "    \n",
    "    return np.divide(result, (n_years*1.00))\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "\n",
    "def calc_lta(file_list):\n",
    "    \n",
    "    if file_list:\n",
    "        \n",
    "        n_years = len(file_list)\n",
    "        agr_period_matrix = get_matrix_list(file_list)\n",
    "        print('Aggregations converted to matrices')\n",
    "        lta = calc_average(agr_period_matrix, n_years)\n",
    "        projection, geotransform, no_data_value, data_type = get_metadata(file_list[0])\n",
    "        \n",
    "        return lta, projection, geotransform, no_data_value, data_type\n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "def write_output(temp_folder, lta, period_start_date, period_end_date, startLTAyear, endLTAyear, product_type, period_N, agr_type, region, projection, geo_transform, image_format, no_data_value, data_type):\n",
    "    \n",
    "    start_day_month = str(period_start_date.month) + '-' + str(period_start_date.day)\n",
    "    end_day_month = str(period_end_date.month) + '-' + str(period_end_date.day)\n",
    "  \n",
    "    output_name = os.path.join(temp_folder, 'LTA_' + product_type + '_' + region + '_' + str(period_N) + '_' + agr_type + '_' + start_day_month + '_' + end_day_month + '_' + str(startLTAyear) + '_' + str(endLTAyear) + '.tif')\n",
    "    \n",
    "    write_output_image(output_name, lta, image_format, data_type, projection, geo_transform, no_data_value=no_data_value)\n",
    "    \n",
    "    return output_name\n",
    "\n",
    "\n",
    "def get_formatted_date(date_str):\n",
    "    date = dt.datetime.strftime(date_str, '%Y-%m-%dT00:00:00Z')\n",
    "    return date\n",
    "\n",
    "\n",
    "def write_properties_file(output_name, first_date, last_date, region_of_interest):\n",
    "    \n",
    "    title = 'Output %s' % output_name\n",
    "    \n",
    "    first_date = get_formatted_date(first_date)\n",
    "    last_date = get_formatted_date(last_date)\n",
    "    \n",
    "    with open(output_name + '.properties', 'wb') as file:\n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (first_date, last_date))\n",
    "        file.write('geometry=%s' % (region_of_interest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Long Term Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Getting metadata' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "input_metada = get_input_metadata(input_references)\n",
    "\n",
    "\n",
    "message = 'computing LTA' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "# N time steps\n",
    "nlist = [N_1['value'], N_3['value'], N_6['value'], N_9['value'], N_12['value'], N_15['value'], N_18['value'], N_27['value'], N_36['value']]\n",
    "nlist = [n == 'True' for n in nlist]\n",
    "nvalues = [1, 3, 6, 9, 12, 15, 18, 27, 36]\n",
    "\n",
    "file_list = []\n",
    "for bl,nv in zip(nlist, nvalues):\n",
    "    \n",
    "    # only works for selected N time steps\n",
    "    if bl:\n",
    "        \n",
    "        N = nv\n",
    "        \n",
    "        file_list = [os.path.join(data_path, os.path.basename(enclosure).split('?')[0]) for enclosure in input_metada['enclosure']]\n",
    "        \n",
    "        lta, projection, geotransform, no_data_value, data_type = calc_lta(file_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK\n",
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(lta)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### write output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Writing output' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "\n",
    "# get start and last date from metadata\n",
    "startdate = input_metada['startdate'].min().strftime('%Y-%m-%d')\n",
    "enddate = input_metada['enddate'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "startLTAyear = int(input_metada['startdate'].min().strftime('%Y'))\n",
    "endLTAyear = int(input_metada['startdate'].max().strftime('%Y'))\n",
    "\n",
    "print(startLTAyear)\n",
    "print(endLTAyear)\n",
    "\n",
    "\n",
    "filename = os.path.splitext(os.path.basename(file_list[0]))[0].split('_')\n",
    "\n",
    "startdate = dt.datetime.strptime(startdate, '%Y-%m-%d')\n",
    "enddate = dt.datetime.strptime(enddate, '%Y-%m-%d')\n",
    "\n",
    "\n",
    "agr = filename[3]\n",
    "prod_type = filename[0]\n",
    "N_value = filename[2]\n",
    "region = filename[1]\n",
    "\n",
    "\n",
    "if lta is not None:\n",
    "\n",
    "    filename = write_output(output_folder, lta, startdate, enddate, startLTAyear, endLTAyear, prod_type, N_value, agr, region, projection, geotransform, 'GTiff', no_data_value, data_type)\n",
    "    print(filename)\n",
    "    write_properties_file(filename, startdate, enddate, regionOfInterest['value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = 'Removing temporary files' \n",
    "ciop.log('INFO', message)\n",
    "\n",
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vacc-env2",
   "language": "python",
   "name": "vacc-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
